{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.callbacks import ReduceLROnPlateau,EarlyStopping\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './input/'\n",
    "comp = 'germeval2018/'\n",
    "TRAIN_DATA_FILE=f'{path}{comp}germeval2018.training.txt'\n",
    "TEST_DATA_FILE=f'{path}{comp}germeval2018.sample.txt'\n",
    "EMBEDDING_FILE=f'{path}embed_tweets_de_200M_200D/embedding_file'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same seed to make classifier output reproducible\n",
    "from numpy.random import seed\n",
    "seed = 1\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 200 # how big is each word vector\n",
    "max_features = 15909 # how many unique words to use (i.e num rows in embedding vector)\n",
    "maxlen = 100 # max number of words in a comment to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import re\n",
    "import sys\n",
    "\n",
    "\n",
    "def preprocess_tweet(tweet):\n",
    "    processed_tweet = []\n",
    "    # Convert to lower case\n",
    "    tweet = tweet.lower()\n",
    "    # Replaces URLs with the word URL\n",
    "    tweet = re.sub(r'((www\\.[\\S]+)|(https?://[\\S]+))', ' URLTOK ', tweet)\n",
    "    # Replace @handle with the word USER_MENTION\n",
    "    tweet = re.sub(r'@[\\S]+', 'USRTOK', tweet)\n",
    "    # Remove RT (retweet)\n",
    "    tweet = re.sub(r'\\brt\\b', 'rt', tweet)\n",
    "    words = tweet.split()\n",
    "\n",
    "    for word in words:\n",
    "        processed_tweet.append(word)\n",
    "\n",
    "    return ' '.join(processed_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in our data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(TRAIN_DATA_FILE, sep=\"\\t\", header=None)\n",
    "#switch columns\n",
    "train = train[[1,0]]\n",
    "train.columns = ['sentiment', 'tweet_text']\n",
    "train.applymap(lambda x: x.strip() if type(x) is str else x)\n",
    "train['tweet_text'] = train['tweet_text'].apply(lambda x: preprocess_tweet(x))\n",
    "\n",
    "mapping = {'OTHER': 0, 'OFFENSE': 1}\n",
    "train = train.replace({'sentiment': mapping})\n",
    "train['sentiment'] = train['sentiment'].astype(np.float32)\n",
    "\n",
    "list_sentences_train = train.tweet_text\n",
    "y_train = train['sentiment'].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'USRTOK USRTOK jetzt bekommt merkel noch grÃ¼ne untergangs-beschleuniger dabei!'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_sentences_train[4672]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(TEST_DATA_FILE, sep=\"\\t\", header=None)\n",
    "#switch column\n",
    "test = test[[1,0]]\n",
    "test.columns = ['sentiment', 'tweet_text']\n",
    "test.applymap(lambda x: x.strip() if type(x) is str else x)\n",
    "test['tweet_text'] = test['tweet_text'].apply(lambda x: preprocess_tweet(x))\n",
    "\n",
    "\n",
    "mapping = {'OTHER': 0, 'OFFENSE': 1}\n",
    "test = test.replace({'sentiment': mapping})\n",
    "test['sentiment'] = test['sentiment'].astype(np.float32)\n",
    "\n",
    "list_sentences_test = test.tweet_text\n",
    "y_test = test.sentiment.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard keras preprocessing, to turn each comment into a list of word indexes of equal length (with truncation or padding as needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(list_sentences_train))\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\n",
    "list_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)\n",
    "X_t = pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
    "X_te = pad_sequences(list_tokenized_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,  2173,    62,  5990],\n",
       "       [    0,     0,     0, ...,  5991,  1318,    18],\n",
       "       [    0,     0,     0, ...,   163,  3737,  3738],\n",
       "       ...,\n",
       "       [    0,     0,     0, ...,   912,    38,   354],\n",
       "       [    0,     0,     0, ...,     3, 15905,  1860],\n",
       "       [    0,     0,     0, ...,  1417,    15, 15908]], dtype=int32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the spinningbytes word vectors (space delimited strings) into a dictionary from word->vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coefs(word,*arr): \n",
    "    return word, np.asarray(arr, dtype='float32')\n",
    "embeddings_index = dict(get_coefs(*o.strip().split()) for o in open(EMBEDDING_FILE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = embeddings_index.values()\n",
    "for val in values:\n",
    "    if len(val) != 200:\n",
    "        print(len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.00042068152, 0.24969141)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_embs = np.stack(embeddings_index.values())\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "emb_mean,emb_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use these vectors to create our embedding matrix, with random initialization for words that aren't in the word embeddings. We'll use the same mean and stdev of embeddings the tweet embeddings have when generating the random init."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words+1, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15909, 200)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.41119985e-02,  1.96115002e-01, -1.42131999e-01,  2.70080008e-02,\n",
       "        7.60390013e-02, -1.41380001e-02, -1.11661002e-01,  2.05010008e-02,\n",
       "       -2.84375012e-01,  1.35187000e-01, -1.72693998e-01,  8.67289975e-02,\n",
       "        1.39009999e-02, -3.25170994e-01,  6.67719990e-02, -5.20679988e-02,\n",
       "       -3.81270014e-02, -2.16638997e-01,  5.86399995e-03,  3.60794991e-01,\n",
       "       -8.77979994e-02, -1.85095996e-01,  2.07589995e-02,  1.25900004e-03,\n",
       "       -1.22977003e-01,  2.16022000e-01,  2.42465004e-01,  1.73329994e-01,\n",
       "       -2.11730003e-02, -1.95577994e-01, -1.56466007e-01, -2.30275005e-01,\n",
       "       -2.05902994e-01, -1.62375003e-01,  1.26438007e-01, -2.16057003e-01,\n",
       "        2.69098997e-01,  9.29099973e-03,  1.08966999e-01, -7.91999977e-03,\n",
       "       -2.48077005e-01,  1.10716000e-01, -1.51537001e-01, -6.63190037e-02,\n",
       "       -4.50860001e-02,  1.17261998e-01, -3.51494998e-01,  1.29637003e-01,\n",
       "       -7.38999981e-04, -3.95597011e-01,  5.18166006e-01, -1.30132005e-01,\n",
       "        4.66998011e-01, -1.87023997e-01,  1.64330006e-01, -4.12230998e-01,\n",
       "        4.64750007e-02,  7.20629990e-02,  3.35189998e-02, -2.12386996e-01,\n",
       "       -8.47500004e-03,  8.76289979e-02,  7.74450004e-02, -9.96579975e-02,\n",
       "       -1.37831002e-01, -1.14868000e-01,  1.66011006e-01, -1.32752001e-01,\n",
       "       -1.00823998e-01,  1.34935006e-01,  5.89655995e-01, -1.42276004e-01,\n",
       "        1.32443994e-01, -1.12112001e-01, -4.09999993e-05, -2.60039996e-02,\n",
       "        1.60147995e-01,  2.18242005e-01,  1.73115000e-01,  4.55287993e-01,\n",
       "        2.38428995e-01, -3.10737014e-01, -1.67235002e-01, -1.57942995e-01,\n",
       "        1.62701994e-01, -1.12207003e-01,  4.23016995e-01, -5.82600012e-02,\n",
       "        1.47181004e-01, -1.98498994e-01,  1.80760995e-01, -2.49522999e-01,\n",
       "        3.21413994e-01,  1.08874999e-01, -5.42199984e-03,  2.65715003e-01,\n",
       "        6.29900023e-02, -1.50610004e-02,  9.66930017e-02,  9.30370018e-02,\n",
       "       -9.04320031e-02,  4.13516998e-01, -1.20839998e-01,  2.69566000e-01,\n",
       "        6.44899998e-03,  4.77700010e-02,  8.89699999e-03, -3.11313987e-01,\n",
       "        6.24199994e-02,  3.55480015e-02, -1.52327999e-01, -6.43030033e-02,\n",
       "        6.16860017e-02, -6.64210021e-02, -6.73919991e-02, -2.62905002e-01,\n",
       "       -3.34165990e-01,  2.17039004e-01,  1.86269000e-01, -2.44253993e-01,\n",
       "        1.45460993e-01, -1.91952005e-01,  2.20513999e-01, -3.29050988e-01,\n",
       "       -1.05040997e-01,  5.48620000e-02, -1.65217996e-01,  9.71390009e-02,\n",
       "        1.37413993e-01,  1.41249998e-02, -1.59757003e-01, -9.95709971e-02,\n",
       "        2.01631993e-01, -4.83729988e-02, -1.13770999e-01, -7.27320015e-02,\n",
       "        1.02398001e-01, -1.40055001e-01,  1.98740009e-02,  1.40465006e-01,\n",
       "        4.76329997e-02, -8.75060037e-02, -3.13704997e-01, -7.58929998e-02,\n",
       "        1.10508002e-01, -8.69799964e-03,  7.65559971e-02,  3.18039991e-02,\n",
       "        5.46590015e-02,  2.42624998e-01, -2.17598006e-01, -5.55670001e-02,\n",
       "       -4.28740010e-02,  5.09930015e-01,  1.93159997e-01, -1.49889998e-02,\n",
       "       -2.17199996e-02, -1.40953004e-01, -1.30217001e-01, -1.44325003e-01,\n",
       "        2.96433985e-01, -3.62343013e-01, -2.70054013e-01,  2.15555996e-01,\n",
       "        3.14134985e-01,  2.99461007e-01, -1.77439991e-02, -1.29475996e-01,\n",
       "        1.18097000e-01,  2.68810000e-02, -1.65039003e-01,  8.17110017e-02,\n",
       "       -4.90799993e-02, -2.39411995e-01, -1.76449001e-01, -1.27600998e-01,\n",
       "        3.29804003e-01,  1.29391998e-01,  4.42879982e-02, -1.02982000e-01,\n",
       "        5.07780015e-02, -1.67629004e-01, -2.95437992e-01, -5.48897028e-01,\n",
       "        2.64570005e-02, -3.03259995e-02,  3.62769999e-02, -1.93312004e-01,\n",
       "        1.61213994e-01,  1.52872995e-01,  1.89035997e-01,  2.69185990e-01,\n",
       "        3.05540003e-02, -4.07199981e-03, -6.89900015e-03, -3.28310013e-01,\n",
       "        1.10708997e-01,  1.44076005e-01,  2.55510006e-02,  1.40963003e-01])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encoding of tweet labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_one_hot = np.zeros((X_t.shape[0], 2))\n",
    "y_train_one_hot[np.arange(X_t.shape[0]),y_train.astype(np.int32)] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple bidirectional LSTM and some dropout (to prevent overfitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4056 samples, validate on 451 samples\n",
      "Epoch 1/10\n",
      "4056/4056 [==============================] - 40s 10ms/step - loss: 0.6452 - acc: 0.6568 - val_loss: 0.6164 - val_acc: 0.6541\n",
      "Epoch 2/10\n",
      "4056/4056 [==============================] - 20s 5ms/step - loss: 0.6148 - acc: 0.6674 - val_loss: 0.5491 - val_acc: 0.7517\n",
      "Epoch 3/10\n",
      "4056/4056 [==============================] - 20s 5ms/step - loss: 0.5012 - acc: 0.7547 - val_loss: 0.4906 - val_acc: 0.7783\n",
      "Epoch 4/10\n",
      "4056/4056 [==============================] - 20s 5ms/step - loss: 0.3420 - acc: 0.8508 - val_loss: 0.4560 - val_acc: 0.7960\n",
      "Epoch 5/10\n",
      "4056/4056 [==============================] - 20s 5ms/step - loss: 0.2119 - acc: 0.9186 - val_loss: 0.5500 - val_acc: 0.7827\n",
      "Epoch 6/10\n",
      "4056/4056 [==============================] - 20s 5ms/step - loss: 0.1346 - acc: 0.9512 - val_loss: 0.6366 - val_acc: 0.7783\n",
      "acc: 76.49%\n",
      "Train on 4057 samples, validate on 451 samples\n",
      "Epoch 1/10\n",
      "4057/4057 [==============================] - 41s 10ms/step - loss: 0.6458 - acc: 0.6613 - val_loss: 0.6177 - val_acc: 0.6674\n",
      "Epoch 2/10\n",
      "4057/4057 [==============================] - 20s 5ms/step - loss: 0.6108 - acc: 0.6704 - val_loss: 0.5325 - val_acc: 0.6896\n",
      "Epoch 3/10\n",
      "4057/4057 [==============================] - 20s 5ms/step - loss: 0.4951 - acc: 0.7624 - val_loss: 0.4409 - val_acc: 0.7783\n",
      "Epoch 4/10\n",
      "4057/4057 [==============================] - 20s 5ms/step - loss: 0.3340 - acc: 0.8580 - val_loss: 0.4266 - val_acc: 0.8049\n",
      "Epoch 5/10\n",
      "4057/4057 [==============================] - 20s 5ms/step - loss: 0.2220 - acc: 0.9118 - val_loss: 0.4765 - val_acc: 0.8093\n",
      "Epoch 6/10\n",
      "4057/4057 [==============================] - 20s 5ms/step - loss: 0.1320 - acc: 0.9537 - val_loss: 0.5861 - val_acc: 0.7916\n",
      "acc: 75.25%\n",
      "Train on 4057 samples, validate on 451 samples\n",
      "Epoch 1/10\n",
      "4057/4057 [==============================] - 41s 10ms/step - loss: 0.6496 - acc: 0.6544 - val_loss: 0.6211 - val_acc: 0.6696\n",
      "Epoch 2/10\n",
      "4057/4057 [==============================] - 20s 5ms/step - loss: 0.6061 - acc: 0.6719 - val_loss: 0.5256 - val_acc: 0.7073\n",
      "Epoch 3/10\n",
      "4057/4057 [==============================] - 20s 5ms/step - loss: 0.4811 - acc: 0.7629 - val_loss: 0.4350 - val_acc: 0.8071\n",
      "Epoch 4/10\n",
      "4057/4057 [==============================] - 21s 5ms/step - loss: 0.3218 - acc: 0.8652 - val_loss: 0.4528 - val_acc: 0.8071\n",
      "Epoch 5/10\n",
      "4057/4057 [==============================] - 20s 5ms/step - loss: 0.2053 - acc: 0.9231 - val_loss: 0.5153 - val_acc: 0.8093\n",
      "acc: 77.05%\n",
      "Train on 4057 samples, validate on 451 samples\n",
      "Epoch 1/10\n",
      "4057/4057 [==============================] - 42s 10ms/step - loss: 0.6463 - acc: 0.6557 - val_loss: 0.6334 - val_acc: 0.6452\n",
      "Epoch 2/10\n",
      "4057/4057 [==============================] - 21s 5ms/step - loss: 0.6027 - acc: 0.6670 - val_loss: 0.5801 - val_acc: 0.6585\n",
      "Epoch 3/10\n",
      "4057/4057 [==============================] - 20s 5ms/step - loss: 0.4968 - acc: 0.7602 - val_loss: 0.4899 - val_acc: 0.7517\n",
      "Epoch 4/10\n",
      "4057/4057 [==============================] - 21s 5ms/step - loss: 0.3406 - acc: 0.8533 - val_loss: 0.5121 - val_acc: 0.7694\n",
      "Epoch 5/10\n",
      "4057/4057 [==============================] - 20s 5ms/step - loss: 0.2145 - acc: 0.9196 - val_loss: 0.5436 - val_acc: 0.7982\n",
      "acc: 79.64%\n",
      "Train on 4057 samples, validate on 451 samples\n",
      "Epoch 1/10\n",
      "4057/4057 [==============================] - 41s 10ms/step - loss: 0.6463 - acc: 0.6603 - val_loss: 0.6248 - val_acc: 0.6674\n",
      "Epoch 2/10\n",
      "4057/4057 [==============================] - 20s 5ms/step - loss: 0.6007 - acc: 0.6835 - val_loss: 0.5375 - val_acc: 0.7073\n",
      "Epoch 3/10\n",
      "4057/4057 [==============================] - 20s 5ms/step - loss: 0.4692 - acc: 0.7846 - val_loss: 0.4733 - val_acc: 0.7716\n",
      "Epoch 4/10\n",
      "4057/4057 [==============================] - 20s 5ms/step - loss: 0.3102 - acc: 0.8755 - val_loss: 0.4979 - val_acc: 0.7938\n",
      "Epoch 5/10\n",
      "4057/4057 [==============================] - 20s 5ms/step - loss: 0.2008 - acc: 0.9211 - val_loss: 0.5400 - val_acc: 0.7982\n",
      "acc: 80.24%\n",
      "Train on 4057 samples, validate on 451 samples\n",
      "Epoch 1/10\n",
      "4057/4057 [==============================] - 41s 10ms/step - loss: 0.6494 - acc: 0.6544 - val_loss: 0.6273 - val_acc: 0.6585\n",
      "Epoch 2/10\n",
      "4057/4057 [==============================] - 20s 5ms/step - loss: 0.6022 - acc: 0.6741 - val_loss: 0.5581 - val_acc: 0.6785\n",
      "Epoch 3/10\n",
      "4057/4057 [==============================] - 20s 5ms/step - loss: 0.4826 - acc: 0.7747 - val_loss: 0.4495 - val_acc: 0.7982\n",
      "Epoch 4/10\n",
      "4057/4057 [==============================] - 20s 5ms/step - loss: 0.3207 - acc: 0.8696 - val_loss: 0.4569 - val_acc: 0.8160\n",
      "Epoch 5/10\n",
      "4057/4057 [==============================] - 20s 5ms/step - loss: 0.1915 - acc: 0.9253 - val_loss: 0.5422 - val_acc: 0.8004\n",
      "acc: 76.45%\n",
      "Train on 4057 samples, validate on 451 samples\n",
      "Epoch 1/10\n",
      "4057/4057 [==============================] - 41s 10ms/step - loss: 0.6417 - acc: 0.6594 - val_loss: 0.6137 - val_acc: 0.6585\n",
      "Epoch 2/10\n",
      "4057/4057 [==============================] - 20s 5ms/step - loss: 0.5949 - acc: 0.6818 - val_loss: 0.5175 - val_acc: 0.7583\n",
      "Epoch 3/10\n",
      "4057/4057 [==============================] - 20s 5ms/step - loss: 0.4544 - acc: 0.7930 - val_loss: 0.4400 - val_acc: 0.7982\n",
      "Epoch 4/10\n",
      "4057/4057 [==============================] - 21s 5ms/step - loss: 0.3050 - acc: 0.8772 - val_loss: 0.5338 - val_acc: 0.7761\n",
      "Epoch 5/10\n",
      "4057/4057 [==============================] - 20s 5ms/step - loss: 0.1832 - acc: 0.9293 - val_loss: 0.6044 - val_acc: 0.8027\n",
      "acc: 76.85%\n",
      "Train on 4057 samples, validate on 451 samples\n",
      "Epoch 1/10\n",
      "4057/4057 [==============================] - 41s 10ms/step - loss: 0.6460 - acc: 0.6596 - val_loss: 0.6135 - val_acc: 0.6718\n",
      "Epoch 2/10\n",
      "4057/4057 [==============================] - 20s 5ms/step - loss: 0.6131 - acc: 0.6670 - val_loss: 0.5435 - val_acc: 0.6874\n",
      "Epoch 3/10\n",
      "4057/4057 [==============================] - 20s 5ms/step - loss: 0.5020 - acc: 0.7501 - val_loss: 0.4542 - val_acc: 0.7694\n",
      "Epoch 4/10\n",
      "4057/4057 [==============================] - 20s 5ms/step - loss: 0.3393 - acc: 0.8526 - val_loss: 0.4639 - val_acc: 0.7960\n",
      "Epoch 5/10\n",
      "4057/4057 [==============================] - 21s 5ms/step - loss: 0.2192 - acc: 0.9184 - val_loss: 0.5718 - val_acc: 0.7849\n",
      "acc: 79.24%\n",
      "Train on 4058 samples, validate on 451 samples\n",
      "Epoch 1/10\n",
      "4058/4058 [==============================] - 41s 10ms/step - loss: 0.6510 - acc: 0.6557 - val_loss: 0.6224 - val_acc: 0.6718\n",
      "Epoch 2/10\n",
      "4058/4058 [==============================] - 20s 5ms/step - loss: 0.6228 - acc: 0.6629 - val_loss: 0.5790 - val_acc: 0.7228\n",
      "Epoch 3/10\n",
      "4058/4058 [==============================] - 20s 5ms/step - loss: 0.5145 - acc: 0.7447 - val_loss: 0.4770 - val_acc: 0.7605\n",
      "Epoch 4/10\n",
      "4058/4058 [==============================] - 20s 5ms/step - loss: 0.3495 - acc: 0.8475 - val_loss: 0.4581 - val_acc: 0.7960\n",
      "Epoch 5/10\n",
      "4058/4058 [==============================] - 20s 5ms/step - loss: 0.2139 - acc: 0.9177 - val_loss: 0.4989 - val_acc: 0.8027\n",
      "Epoch 6/10\n",
      "4058/4058 [==============================] - 20s 5ms/step - loss: 0.1305 - acc: 0.9490 - val_loss: 0.6152 - val_acc: 0.7894\n",
      "acc: 74.60%\n",
      "Train on 4058 samples, validate on 451 samples\n",
      "Epoch 1/10\n",
      "4058/4058 [==============================] - 41s 10ms/step - loss: 0.6498 - acc: 0.6597 - val_loss: 0.6302 - val_acc: 0.6652\n",
      "Epoch 2/10\n",
      "4058/4058 [==============================] - 20s 5ms/step - loss: 0.6200 - acc: 0.6641 - val_loss: 0.5694 - val_acc: 0.7295\n",
      "Epoch 3/10\n",
      "4058/4058 [==============================] - 21s 5ms/step - loss: 0.5111 - acc: 0.7366 - val_loss: 0.4769 - val_acc: 0.7938\n",
      "Epoch 4/10\n",
      "4058/4058 [==============================] - 20s 5ms/step - loss: 0.3545 - acc: 0.8457 - val_loss: 0.4596 - val_acc: 0.7938\n",
      "Epoch 5/10\n",
      "4058/4058 [==============================] - 20s 5ms/step - loss: 0.2141 - acc: 0.9182 - val_loss: 0.5346 - val_acc: 0.7627\n",
      "Epoch 6/10\n",
      "4058/4058 [==============================] - 20s 5ms/step - loss: 0.1240 - acc: 0.9574 - val_loss: 0.6396 - val_acc: 0.7916\n",
      "acc: 80.20%\n",
      "77.60% (+/- 1.96%)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "# define 10-fold cross validation test harness\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "cvscores = []\n",
    "for train, test in kfold.split(X_t, y_train):\n",
    "    inp = Input(shape=(maxlen,))\n",
    "    x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
    "    x = Bidirectional(LSTM(64, return_sequences=True, dropout=0.5, recurrent_dropout=0.5))(x) # changed to GRU (from LSTM)\n",
    "    #x = Conv1D(64, kernel_size = 5, activation='relu')(x)\n",
    "    x = GlobalMaxPool1D()(x) \n",
    "    #avg_pool = GlobalAveragePooling1D()(x)\n",
    "    #max_pool = GlobalMaxPooling1D()(x)\n",
    "    #x = concatenate([avg_pool, max_pool])\n",
    "    x = Dense(64, activation=\"relu\")(x)\n",
    "    x = Dropout(0.5)(x) # increased dropout because of overfitting (0.5 with 3 epochs seems good)\n",
    "    x = Dense(2, activation=\"softmax\")(x) \n",
    "    \n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "    \n",
    "    adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    rmsprop = optimizers.Adam(lr=0.001)\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy']) #changed optimizer from 'adam' to custom adam\n",
    "    \n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=0.000001)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')\n",
    "\n",
    "    model.fit(X_t[train], y_train_one_hot[train], batch_size=32, epochs=10, validation_split=0.1, shuffle=True, callbacks=[reduce_lr,early_stopping]);\n",
    "\n",
    "    scores = model.evaluate(X_t[test], y_train_one_hot[test], verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "    \n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serialize Model to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "#from keras.models import model_from_json\n",
    "# serialize model to JSON\n",
    "#model_json = model.to_json()\n",
    "#with open(\"LSTM_model.json\", \"w\") as json_file:\n",
    "#    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "#model.save_weights(\"LSTM_model.h5\")\n",
    "#print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# load json and create model\n",
    "json_file = open('LSTM_model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"LSTM_model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "loaded_model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 18s 178ms/step\n",
      "0.007993052\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_te, batch_size=32, verbose=1) \n",
    "print(preds[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9\n"
     ]
    }
   ],
   "source": [
    "pred_pos = preds.argmax(-1)\n",
    "pred_pos = pred_pos.astype(float)\n",
    "print('Accuracy: ' + str(np.mean(pred_pos == y_test))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.85      0.98      0.91        51\n",
      "        1.0       0.98      0.82      0.89        49\n",
      "\n",
      "avg / total       0.91      0.90      0.90       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print(classification_report(y_test, pred_pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a submission\n",
    "submission = pd.DataFrame(columns=['tweet_text', 'probabilities_neutral', 'probabilities_toxic'])\n",
    "# read original tweet text\n",
    "test = pd.read_csv(TEST_DATA_FILE, sep=\"\\t\", header=None)\n",
    "submission['tweet_text'] = test[0].values \n",
    "# convert predictions \n",
    "submission['probabilities_neutral'] = preds[:,0] \n",
    "submission['probabilities_toxic'] = preds[:,1]\n",
    "# dummy value\n",
    "submission.to_csv(f\"{path}{comp}LSTM_probabilities.csv\", sep=\"\\t\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a submission\n",
    "submission = pd.DataFrame(columns=['tweet_text', 'binary', 'multiclass'])\n",
    "# read original tweet text\n",
    "test = pd.read_csv(TEST_DATA_FILE, sep=\"\\t\", header=None)\n",
    "submission['tweet_text'] = test[0].values \n",
    "# convert predictions \n",
    "submission['binary'] = pred_pos \n",
    "mapping = {0 :'OTHER', 1: 'OFFENSE'}\n",
    "submission = submission.replace({'binary': mapping})\n",
    "# dummy value\n",
    "submission['multiclass'] = 'OTHER'\n",
    "submission.to_csv(f\"{path}{comp}LSTM_submit.csv\", sep=\"\\t\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Receiver Operating Characteristcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_one_hot = np.zeros((X_te.shape[0], 2))\n",
    "y_test_one_hot[np.arange(X_te.shape[0]),y_test.astype(np.int32)] = 1\n",
    "pred_pos_one_hot = np.zeros((X_te.shape[0], 2))\n",
    "pred_pos_one_hot[np.arange(X_te.shape[0]),pred_pos.astype(np.int32)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy import interp\n",
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(2):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test, preds[:,i])\n",
    "\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr[1], tpr[1], color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[1])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('LSTM - Receiver operating characteristic metric')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[50,  1],\n",
       "       [ 9, 40]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, pred_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
